{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76a85f60",
   "metadata": {},
   "source": [
    "# 02 ARIMA Modeling\n",
    "- ARIMA/SARIMA model for TSLA\n",
    "- Parameter tuning (auto_arima)\n",
    "- Model evaluation (MAE, RMSE, MAPE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28fce42",
   "metadata": {},
   "source": [
    "# 02 ARIMA Modeling\n",
    "This notebook demonstrates how to build, tune, and evaluate an ARIMA/SARIMA model for TSLA stock price forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8091f715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima import auto_arima\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f22824a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range in data: 1970-01-01 00:00:00.000000021 to 1970-01-01 00:00:00.000002536\n",
      "                                    Price      Close       High        Low  \\\n",
      "Date                                                                         \n",
      "1970-01-01 00:00:00.000000021  2015-07-29  17.587999  17.859333  17.466667   \n",
      "1970-01-01 00:00:00.000000022  2015-07-30  17.785999  17.796000  17.474001   \n",
      "1970-01-01 00:00:00.000000023  2015-07-31  17.743334  17.957333  17.674667   \n",
      "1970-01-01 00:00:00.000000024  2015-08-03  17.332666  17.780666  17.138000   \n",
      "1970-01-01 00:00:00.000000025  2015-08-04  17.752001  17.781334  17.222668   \n",
      "\n",
      "                                    Open      Volume  Adj Close    Return  \\\n",
      "Date                                                                        \n",
      "1970-01-01 00:00:00.000000021  17.618000  41851500.0  17.587999 -0.003776   \n",
      "1970-01-01 00:00:00.000000022  17.512667  30519000.0  17.785999  0.011258   \n",
      "1970-01-01 00:00:00.000000023  17.840000  33339000.0  17.743334 -0.002399   \n",
      "1970-01-01 00:00:00.000000024  17.752666  38302500.0  17.332666 -0.023145   \n",
      "1970-01-01 00:00:00.000000025  17.334000  35287500.0  17.752001  0.024193   \n",
      "\n",
      "                               LogReturn  Volatility  RollingMean  RollingStd  \\\n",
      "Date                                                                            \n",
      "1970-01-01 00:00:00.000000021  -0.003783    0.027928    17.782222    0.510910   \n",
      "1970-01-01 00:00:00.000000022   0.011195    0.028048    17.774730    0.509581   \n",
      "1970-01-01 00:00:00.000000023  -0.002402    0.028052    17.765206    0.508140   \n",
      "1970-01-01 00:00:00.000000024  -0.023417    0.026862    17.701619    0.471766   \n",
      "1970-01-01 00:00:00.000000025   0.023905    0.027519    17.658952    0.419520   \n",
      "\n",
      "                                z_score  Open_scaled  High_scaled  Low_scaled  \\\n",
      "Date                                                                            \n",
      "1970-01-01 00:00:00.000000021 -0.150330    -0.945230    -0.946200   -0.944037   \n",
      "1970-01-01 00:00:00.000000022  0.253040    -0.946101    -0.946712   -0.943974   \n",
      "1970-01-01 00:00:00.000000023 -0.113374    -0.943396    -0.945408   -0.942273   \n",
      "1970-01-01 00:00:00.000000024 -0.670005    -0.944118    -0.946836   -0.946823   \n",
      "1970-01-01 00:00:00.000000025  0.600112    -0.947577    -0.946830   -0.946105   \n",
      "\n",
      "                               Close_scaled  Adj Close_scaled  Volume_scaled  \n",
      "Date                                                                          \n",
      "1970-01-01 00:00:00.000000021     -0.946100         -0.946100      -0.986637  \n",
      "1970-01-01 00:00:00.000000022     -0.944462         -0.944462      -1.141226  \n",
      "1970-01-01 00:00:00.000000023     -0.944815         -0.944815      -1.102758  \n",
      "1970-01-01 00:00:00.000000024     -0.948212         -0.948212      -1.035050  \n",
      "1970-01-01 00:00:00.000000025     -0.944743         -0.944743      -1.076178  \n",
      "split_date 2024-01-01 is outside the data range. Please adjust it.\n"
     ]
    }
   ],
   "source": [
    "# Load processed TSLA data with robust date parsing and validation\n",
    "file_path = '../data/processed/TSLA_processed.csv'\n",
    "df = pd.read_csv(file_path, parse_dates=['Date'])  # Ensure Date is parsed as datetime\n",
    "\n",
    "# Check for missing or malformed dates\n",
    "if df['Date'].isnull().any():\n",
    "    print(\"Warning: There are missing or malformed dates in your data.\")\n",
    "    df = df.dropna(subset=['Date'])\n",
    "\n",
    "df = df.set_index('Date').sort_index()\n",
    "print(\"Date range in data:\", df.index.min(), \"to\", df.index.max())\n",
    "print(df.head())\n",
    "\n",
    "# Choose a split_date that is within your data's date range\n",
    "split_date = '2024-01-01'\n",
    "if split_date < str(df.index.min()) or split_date > str(df.index.max()):\n",
    "    print(f\"split_date {split_date} is outside the data range. Please adjust it.\")\n",
    "else:\n",
    "    # Split data into train and test sets\n",
    "    train = df.loc[df.index < split_date, 'Adj Close']\n",
    "    test = df.loc[df.index >= split_date, 'Adj Close']\n",
    "    print(f\"Train shape: {train.shape}, Test shape: {test.shape}\")\n",
    "    print(f\"Train range: {train.index.min()} to {train.index.max()}\")\n",
    "    print(f\"Test range: {test.index.min()} to {test.index.max()}\")\n",
    "\n",
    "    # Only proceed if test set is not empty\n",
    "    n_test = len(test)\n",
    "    if n_test > 0:\n",
    "        # Use auto_arima to find the best (p,d,q) parameters\n",
    "        print('Running auto_arima for parameter selection...')\n",
    "        stepwise_model = auto_arima(train, start_p=1, start_q=1, max_p=3, max_q=3, m=1,\n",
    "                                    start_P=0, seasonal=False, d=None, trace=True,\n",
    "                                    error_action='ignore', suppress_warnings=True, stepwise=True)\n",
    "        print(f'Best ARIMA order: {stepwise_model.order}')\n",
    "\n",
    "        # Fit SARIMAX model with the best parameters\n",
    "        order = stepwise_model.order\n",
    "        model = SARIMAX(train, order=order, enforce_stationarity=False, enforce_invertibility=False)\n",
    "        model_fit = model.fit(disp=False)\n",
    "        print(model_fit.summary())\n",
    "\n",
    "        # Forecast over the test set period\n",
    "        forecast = model_fit.forecast(steps=n_test)\n",
    "        forecast = pd.Series(forecast, index=test.index)\n",
    "\n",
    "        # Plot actual vs forecast\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(train.index, train, label='Train')\n",
    "        plt.plot(test.index, test, label='Test', color='orange')\n",
    "        plt.plot(forecast.index, forecast, label='Forecast', color='green')\n",
    "        plt.title('ARIMA Forecast vs Actual')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Adj Close')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        # Evaluate forecast performance\n",
    "        mae = mean_absolute_error(test, forecast)\n",
    "        rmse = np.sqrt(mean_squared_error(test, forecast))\n",
    "        mape = np.mean(np.abs((test - forecast) / test)) * 100\n",
    "        print(f'MAE: {mae:.4f}')\n",
    "        print(f'RMSE: {rmse:.4f}')\n",
    "        print(f'MAPE: {mape:.2f}%')\n",
    "\n",
    "        # Plot residuals to check for patterns\n",
    "        residuals = test - forecast\n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.plot(residuals)\n",
    "        plt.title('Forecast Residuals (Test - Forecast)')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Residual')\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(6,4))\n",
    "        plt.hist(residuals, bins=30, edgecolor='k')\n",
    "        plt.title('Distribution of Residuals')\n",
    "        plt.xlabel('Residual')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Test set is empty after splitting. Adjust your split_date or check your data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb8c35a",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "- Summarize the model's performance and discuss any patterns or issues observed in the residuals.\n",
    "- Consider next steps: further tuning, adding exogenous variables, or comparing with LSTM."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
